{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4Aut7YBvk0+skN396Xzqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chi36/Final/blob/main/ChEG_672_Data_Science_in_Chemical_engineering_Final_Exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "PihKOvj8DA8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset and display first few rows"
      ],
      "metadata": {
        "id": "jwIGD1cFFNQ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNO4RmJKC2bZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4998c388-be0b-4a3f-802d-c897eec4576b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Input variables Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
            "0                Biomass type    C (wt%)    H (wt%)    N (wt%)    O (wt%)   \n",
            "1                Pinus leaves       46.6        7.4        1.3       44.7   \n",
            "2   Cupressus funebris leaves         43        6.8        0.7       49.6   \n",
            "3             Platanus leaves       45.3        7.7        0.7       46.2   \n",
            "4  Cinnamomum camphora leaves       43.5        7.4        1.4       47.8   \n",
            "\n",
            "  Unnamed: 5 Unnamed: 6                  Unnamed: 7       Unnamed: 8  \\\n",
            "0    S (wt%)    Ash (%)  Operating dry matter (wt%)  Temprature (Â°C)   \n",
            "1        0.1        1.3                          10              300   \n",
            "2        0.1        7.4                          10              300   \n",
            "3        0.1          6                          10              300   \n",
            "4        0.1          8                          10              300   \n",
            "\n",
            "             Unnamed: 9  ...        Output variables              Unnamed: 12  \\\n",
            "0  Residence time (min)  ...  Biocrude oil yield (%)  Aqueous phase yield (%)   \n",
            "1                    30  ...                      33                      NaN   \n",
            "2                    30  ...                    36.5                      NaN   \n",
            "3                    30  ...                    29.5                      NaN   \n",
            "4                    30  ...                      39                      NaN   \n",
            "\n",
            "        Unnamed: 13          Unnamed: 14                    Unnamed: 15  \\\n",
            "0  Syngas yield (%)  Hydrochar yield (%)  Biocrude carbon content (wt%)   \n",
            "1               NaN                 25.4                          66.86   \n",
            "2               NaN                 25.6                          65.96   \n",
            "3               NaN                 25.4                           65.9   \n",
            "4               NaN                   15                          70.43   \n",
            "\n",
            "                       Unnamed: 16                      Unnamed: 17  \\\n",
            "0  Biocrude hydrogen content (wt%)  Biocrude nitrogen content (wt%)   \n",
            "1                             7.08                             1.15   \n",
            "2                             6.82                             1.11   \n",
            "3                             6.24                             0.73   \n",
            "4                             7.86                             1.74   \n",
            "\n",
            "                     Unnamed: 18                    Unnamed: 19  \\\n",
            "0  Biocrude oxygen content (wt%)  Biocrude sulfur content (wt%)   \n",
            "1                          25.98                           0.04   \n",
            "2                          26.17                           0.05   \n",
            "3                          27.13                           0.04   \n",
            "4                          19.97                           0.04   \n",
            "\n",
            "                        Unnamed: 20  \n",
            "0  Biocrude calorific value (MJ/kg)  \n",
            "1                             28.16  \n",
            "2                             27.41  \n",
            "3                             26.39  \n",
            "4                             31.56  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel('/content/dataset 4 HTL.xlsx')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check for duplicates"
      ],
      "metadata": {
        "id": "FvDblflFFTpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset into a pandas DataFrame\n",
        "df = pd.read_excel('/content/dataset 4 HTL.xlsx')\n",
        "\n",
        "# Check for duplicates\n",
        "duplicates = df[df.duplicated()]\n",
        "\n",
        "# Print the duplicated rows\n",
        "if not duplicates.empty:\n",
        "    print(\"Duplicate rows found:\")\n",
        "    print(duplicates)\n",
        "else:\n",
        "    print(\"No duplicates found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTl-0mE2FWGl",
        "outputId": "111f4836-8ca2-444f-83df-a1526a20422f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate rows found:\n",
            "         Input variables Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
            "92           Poplar wood      46.72       6.18        0.1      46.96   \n",
            "423  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "424  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "425  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "426  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "427  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "428  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "429  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "430  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "431  Palm mesocarp fiber      46.29       4.67       1.42      47.37   \n",
            "432    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "433    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "434    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "435    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "436    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "437    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "438    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "439    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "440    Palm kernel shell      47.77       4.06       0.46      47.55   \n",
            "515   Olive oil residues      50.58       6.23       1.49      41.58   \n",
            "545     Alm kernel shell      50.31       6.05       0.46      43.18   \n",
            "574          Scenedesmus       52.1        7.4        8.8       31.1   \n",
            "575            Spirulina       45.2        6.4        9.8       37.8   \n",
            "\n",
            "    Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ...  \\\n",
            "92        0.04       0.92         10        300         10  ...   \n",
            "423       0.24       24.1         10        330         60  ...   \n",
            "424       0.24       24.1         10        330         60  ...   \n",
            "425       0.24       24.1         10        330         60  ...   \n",
            "426       0.24       24.1         10        360         60  ...   \n",
            "427       0.24       24.1         10        360         60  ...   \n",
            "428       0.24       24.1         10        360         60  ...   \n",
            "429       0.24       24.1         10        390         60  ...   \n",
            "430       0.24       24.1         10        390         60  ...   \n",
            "431       0.24       24.1         10        390         60  ...   \n",
            "432       0.16       19.1         10        330         60  ...   \n",
            "433       0.16       19.1         10        330         60  ...   \n",
            "434       0.16       19.1         10        330         60  ...   \n",
            "435       0.16       19.1         10        360         60  ...   \n",
            "436       0.16       19.1         10        360         60  ...   \n",
            "437       0.16       19.1         10        360         60  ...   \n",
            "438       0.16       19.1         10        390         60  ...   \n",
            "439       0.16       19.1         10        390         60  ...   \n",
            "440       0.16       19.1         10        390         60  ...   \n",
            "515       0.12       1.86         10        300         15  ...   \n",
            "545          0       4.61         20        390         60  ...   \n",
            "574       0.48          6         20        300         30  ...   \n",
            "575        0.8         11         20        300         30  ...   \n",
            "\n",
            "    Output variables Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15  \\\n",
            "92              17.5         NaN         NaN       32.11         NaN   \n",
            "423             16.4         NaN         NaN         NaN         NaN   \n",
            "424            15.72         NaN         NaN         NaN         NaN   \n",
            "425            14.79         NaN         NaN         NaN         NaN   \n",
            "426            22.71         NaN         NaN         NaN         NaN   \n",
            "427            23.22         NaN         NaN         NaN         NaN   \n",
            "428            21.75         NaN         NaN         NaN         NaN   \n",
            "429            34.32         NaN         NaN         NaN         NaN   \n",
            "430            27.57         NaN         NaN         NaN         NaN   \n",
            "431            24.07         NaN         NaN         NaN         NaN   \n",
            "432            22.83         NaN         NaN         NaN         NaN   \n",
            "433            25.62         NaN         NaN         NaN         NaN   \n",
            "434            23.67         NaN         NaN         NaN         NaN   \n",
            "435            26.55         NaN         NaN         NaN         NaN   \n",
            "436            27.54         NaN         NaN         NaN         NaN   \n",
            "437            23.44         NaN         NaN         NaN         NaN   \n",
            "438            38.53         NaN         NaN         NaN         NaN   \n",
            "439            31.16         NaN         NaN         NaN         NaN   \n",
            "440            29.35         NaN         NaN         NaN         NaN   \n",
            "515               30         NaN         NaN         NaN       68.36   \n",
            "545            15.55         NaN         NaN         NaN         NaN   \n",
            "574               45          17          30           7        72.6   \n",
            "575               31          23          35          11        72.2   \n",
            "\n",
            "    Unnamed: 16 Unnamed: 17 Unnamed: 18 Unnamed: 19 Unnamed: 20  \n",
            "92          NaN         NaN         NaN         NaN         NaN  \n",
            "423         NaN         NaN         NaN         NaN         NaN  \n",
            "424         NaN         NaN         NaN         NaN         NaN  \n",
            "425         NaN         NaN         NaN         NaN         NaN  \n",
            "426         NaN         NaN         NaN         NaN         NaN  \n",
            "427         NaN         NaN         NaN         NaN         NaN  \n",
            "428         NaN         NaN         NaN         NaN         NaN  \n",
            "429         NaN         NaN         NaN         NaN         NaN  \n",
            "430         NaN         NaN         NaN         NaN         NaN  \n",
            "431         NaN         NaN         NaN         NaN         NaN  \n",
            "432         NaN         NaN         NaN         NaN         NaN  \n",
            "433         NaN         NaN         NaN         NaN         NaN  \n",
            "434         NaN         NaN         NaN         NaN         NaN  \n",
            "435         NaN         NaN         NaN         NaN         NaN  \n",
            "436         NaN         NaN         NaN         NaN         NaN  \n",
            "437         NaN         NaN         NaN         NaN         NaN  \n",
            "438         NaN         NaN         NaN         NaN         NaN  \n",
            "439         NaN         NaN         NaN         NaN         NaN  \n",
            "440         NaN         NaN         NaN         NaN         NaN  \n",
            "515        7.54        1.02       22.99        0.09       29.78  \n",
            "545         NaN         NaN         NaN         NaN        16.1  \n",
            "574           9         6.5        10.5        1.35        35.5  \n",
            "575         9.1         8.1         9.2        1.41        35.8  \n",
            "\n",
            "[23 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handle missing values"
      ],
      "metadata": {
        "id": "f2ucI_4FEFP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset into a DataFrame\n",
        "df = pd.read_excel('/content/dataset 4 HTL.xlsx')\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Print the count of missing values for each column\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Check if there are any missing values in the entire DataFrame\n",
        "has_missing_values = df.isnull().any().any()\n",
        "print(\"Has missing values:\", has_missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWeYC18pEJc9",
        "outputId": "3d498a75-d29f-4924-8a7b-b65bf9312c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Input variables       0\n",
            "Unnamed: 1            0\n",
            "Unnamed: 2            0\n",
            "Unnamed: 3            0\n",
            "Unnamed: 4            0\n",
            "Unnamed: 5            0\n",
            "Unnamed: 6            0\n",
            "Unnamed: 7            0\n",
            "Unnamed: 8            0\n",
            "Unnamed: 9            0\n",
            "Unnamed: 10           0\n",
            "Output variables      0\n",
            "Unnamed: 12         453\n",
            "Unnamed: 13         434\n",
            "Unnamed: 14         310\n",
            "Unnamed: 15         382\n",
            "Unnamed: 16         382\n",
            "Unnamed: 17         382\n",
            "Unnamed: 18         382\n",
            "Unnamed: 19         387\n",
            "Unnamed: 20         358\n",
            "dtype: int64\n",
            "Has missing values: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputation for missing values**"
      ],
      "metadata": {
        "id": "JkNjgvHLGkaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Step 1: Load the dataset (replace with your actual file path)\n",
        "file_path = '/content/dataset 4 HTL.xlsx'  # Provide your actual file path\n",
        "try:\n",
        "    df = pd.read_excel(file_path)  # Read the dataset\n",
        "    print(f\"Data loaded successfully from {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Identify numerical columns and exclude non-relevant columns like 'Unnamed'\n",
        "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns  # Select numerical columns\n",
        "numerical_columns = [col for col in numerical_columns if 'Unnamed' not in col]  # Remove 'Unnamed' columns\n",
        "print(\"\\nNumerical columns identified:\", numerical_columns)  # Debugging: Check the numerical columns\n",
        "\n",
        "# Step 3: Impute missing values for numerical columns (using median)\n",
        "if len(numerical_columns) > 0:\n",
        "    print(\"\\nImputing missing values for numerical columns...\")\n",
        "    imputer_num = SimpleImputer(strategy='median')  # Imputer for numerical columns (median strategy)\n",
        "\n",
        "    # Apply the imputation to numerical columns\n",
        "    df[numerical_columns] = imputer_num.fit_transform(df[numerical_columns])\n",
        "    print(\"Numerical columns imputation completed.\")\n",
        "else:\n",
        "    print(\"No numerical columns found for imputation.\")\n",
        "\n",
        "# Step 4: Verify the imputation results (check if there are any remaining missing values)\n",
        "print(\"\\nAfter imputation, missing data summary:\")\n",
        "missing_data_summary = df.isnull().sum()  # Get the number of missing values in each column\n",
        "print(missing_data_summary)  # Print the summary to check if any values remain missing\n",
        "\n",
        "# Step 5: Optionally, save the cleaned dataset to a new Excel file\n",
        "output_file = 'cleaned_data_numerical_imputed.xlsx'  # Specify the output file path\n",
        "df.to_excel(output_file, index=False)  # Save the cleaned dataset to a new Excel file\n",
        "print(f\"Cleaned data saved to {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s5AT4QRGomu",
        "outputId": "18d150e0-0879-45a7-9bd7-229d97243256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully from /content/dataset 4 HTL.xlsx\n",
            "\n",
            "Numerical columns identified: []\n",
            "No numerical columns found for imputation.\n",
            "\n",
            "After imputation, missing data summary:\n",
            "Input variables       0\n",
            "Unnamed: 1            0\n",
            "Unnamed: 2            0\n",
            "Unnamed: 3            0\n",
            "Unnamed: 4            0\n",
            "Unnamed: 5            0\n",
            "Unnamed: 6            0\n",
            "Unnamed: 7            0\n",
            "Unnamed: 8            0\n",
            "Unnamed: 9            0\n",
            "Unnamed: 10           0\n",
            "Output variables      0\n",
            "Unnamed: 12         453\n",
            "Unnamed: 13         434\n",
            "Unnamed: 14         310\n",
            "Unnamed: 15         382\n",
            "Unnamed: 16         382\n",
            "Unnamed: 17         382\n",
            "Unnamed: 18         382\n",
            "Unnamed: 19         387\n",
            "Unnamed: 20         358\n",
            "dtype: int64\n",
            "Cleaned data saved to cleaned_data_numerical_imputed.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-Hot Encoding"
      ],
      "metadata": {
        "id": "si0yYCDlIos9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset (replace with your actual file path)\n",
        "file_path = '/content/dataset 4 HTL.xlsx'  # Replace with your actual file path\n",
        "try:\n",
        "    df = pd.read_excel(file_path)  # Read the dataset\n",
        "    print(f\"Data loaded successfully from {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Identify categorical columns (excluding numerical ones)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns  # Identify categorical columns\n",
        "print(\"\\nCategorical columns identified:\", categorical_columns)  # Debugging: Check the categorical columns\n",
        "\n",
        "# Step 3: Apply One-Hot Encoding to categorical columns\n",
        "if len(categorical_columns) > 0:\n",
        "    print(\"\\nApplying One-Hot Encoding to categorical columns...\")\n",
        "\n",
        "    # Perform One-Hot Encoding using pandas get_dummies\n",
        "    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=False)\n",
        "\n",
        "    print(\"One-Hot Encoding completed.\")\n",
        "else:\n",
        "    print(\"No categorical columns found for One-Hot Encoding.\")\n",
        "\n",
        "# Step 4: Check the result after encoding (first few rows)\n",
        "print(\"\\nFirst few rows of the dataset after One-Hot Encoding:\")\n",
        "print(df_encoded.head())\n",
        "\n",
        "# Step 5: Optionally, save the encoded dataset to a new Excel file\n",
        "output_file = 'one_hot_encoded_data.xlsx'  # Specify the output file path\n",
        "df_encoded.to_excel(output_file, index=False)  # Save the encoded dataset to a new Excel file\n",
        "print(f\"One-Hot Encoded data saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv30KUQ-Is_N",
        "outputId": "8671eaa7-b8f5-4e5f-b9d5-40c229e3e183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully from /content/dataset 4 HTL.xlsx\n",
            "\n",
            "Categorical columns identified: Index(['Input variables', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3',\n",
            "       'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',\n",
            "       'Unnamed: 9', 'Unnamed: 10', 'Output variables', 'Unnamed: 12',\n",
            "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
            "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20'],\n",
            "      dtype='object')\n",
            "\n",
            "Applying One-Hot Encoding to categorical columns...\n",
            "One-Hot Encoding completed.\n",
            "\n",
            "First few rows of the dataset after One-Hot Encoding:\n",
            "   Input variables_25%C. pyrenoidosa macro algae+75%starch-rich biomass waste  \\\n",
            "0                                              False                            \n",
            "1                                              False                            \n",
            "2                                              False                            \n",
            "3                                              False                            \n",
            "4                                              False                            \n",
            "\n",
            "   Input variables_25%Monoraphidium sp+75%Domestic sewage sludge  \\\n",
            "0                                              False               \n",
            "1                                              False               \n",
            "2                                              False               \n",
            "3                                              False               \n",
            "4                                              False               \n",
            "\n",
            "   Input variables_34%C. pyrenoidosa macro algae+66%starch-rich biomass waste  \\\n",
            "0                                              False                            \n",
            "1                                              False                            \n",
            "2                                              False                            \n",
            "3                                              False                            \n",
            "4                                              False                            \n",
            "\n",
            "   Input variables_50%C. pyrenoidosa macro algae+50%starch-rich biomass waste  \\\n",
            "0                                              False                            \n",
            "1                                              False                            \n",
            "2                                              False                            \n",
            "3                                              False                            \n",
            "4                                              False                            \n",
            "\n",
            "   Input variables_50%Desmodesmus sp+ 50%Sugar beet pulp  \\\n",
            "0                                              False       \n",
            "1                                              False       \n",
            "2                                              False       \n",
            "3                                              False       \n",
            "4                                              False       \n",
            "\n",
            "   Input variables_50%Desmodesmus sp+50%pine wood  \\\n",
            "0                                           False   \n",
            "1                                           False   \n",
            "2                                           False   \n",
            "3                                           False   \n",
            "4                                           False   \n",
            "\n",
            "   Input variables_50%Monoraphidium sp+50%Domestic sewage sludge  \\\n",
            "0                                              False               \n",
            "1                                              False               \n",
            "2                                              False               \n",
            "3                                              False               \n",
            "4                                              False               \n",
            "\n",
            "   Input variables_50%pine wood +50% Sugar beet pulp  \\\n",
            "0                                              False   \n",
            "1                                              False   \n",
            "2                                              False   \n",
            "3                                              False   \n",
            "4                                              False   \n",
            "\n",
            "   Input variables_66%C. pyrenoidosa macro algae+34%starch-rich biomass waste  \\\n",
            "0                                              False                            \n",
            "1                                              False                            \n",
            "2                                              False                            \n",
            "3                                              False                            \n",
            "4                                              False                            \n",
            "\n",
            "   Input variables_75%C. pyrenoidosa macro algae+25%starch-rich biomass waste  \\\n",
            "0                                              False                            \n",
            "1                                              False                            \n",
            "2                                              False                            \n",
            "3                                              False                            \n",
            "4                                              False                            \n",
            "\n",
            "   ...  Unnamed: 20_40.38  Unnamed: 20_40.4  Unnamed: 20_40.67  \\\n",
            "0  ...              False             False              False   \n",
            "1  ...              False             False              False   \n",
            "2  ...              False             False              False   \n",
            "3  ...              False             False              False   \n",
            "4  ...              False             False              False   \n",
            "\n",
            "   Unnamed: 20_40.85  Unnamed: 20_41.42  Unnamed: 20_43.34  Unnamed: 20_44.11  \\\n",
            "0              False              False              False              False   \n",
            "1              False              False              False              False   \n",
            "2              False              False              False              False   \n",
            "3              False              False              False              False   \n",
            "4              False              False              False              False   \n",
            "\n",
            "   Unnamed: 20_44.38  Unnamed: 20_51.5  \\\n",
            "0              False             False   \n",
            "1              False             False   \n",
            "2              False             False   \n",
            "3              False             False   \n",
            "4              False             False   \n",
            "\n",
            "   Unnamed: 20_Biocrude calorific value (MJ/kg)  \n",
            "0                                          True  \n",
            "1                                         False  \n",
            "2                                         False  \n",
            "3                                         False  \n",
            "4                                         False  \n",
            "\n",
            "[5 rows x 3549 columns]\n",
            "One-Hot Encoded data saved to one_hot_encoded_data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Outliers"
      ],
      "metadata": {
        "id": "wdZ8cAprF1QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset into a pandas DataFrame\n",
        "df = pd.read_excel('/content/one_hot_encoded_data.xlsx')\n",
        "\n",
        "# Define a function to identify outliers using the IQR method\n",
        "def detect_outliers_iqr(df):\n",
        "    outliers = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "    # Iterate over each column in the dataframe\n",
        "    for column in df.select_dtypes(include=['float64', 'int64']).columns:  # Only consider numeric columns\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Define the lower and upper bounds for outliers\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Identify the rows where the values are outliers\n",
        "        column_outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "        # Append the outliers to the outliers dataframe\n",
        "        if not column_outliers.empty:\n",
        "            outliers = pd.concat([outliers, column_outliers], axis=0)\n",
        "\n",
        "    return outliers\n",
        "\n",
        "# Get the outliers\n",
        "outliers = detect_outliers_iqr(df)\n",
        "\n",
        "# Print the outliers if any exist\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers detected:\")\n",
        "    print(outliers)\n",
        "else:\n",
        "    print(\"No outliers detected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0TkgwkHF6IS",
        "outputId": "6003d913-df0c-4e8c-ae15-6662cd56f251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No outliers detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Correlation Analysis"
      ],
      "metadata": {
        "id": "DydebFp0E4N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import shap\n",
        "from skopt import BayesSearchCV, gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "import math\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "import joblib\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NOb5QFjySni9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Machine Learning Models"
      ],
      "metadata": {
        "id": "OobTBsguJZQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/cleaned_data_no_missing_values_numerical.xlsx')\n",
        "\n",
        "# Remove the first column (only the first column)\n",
        "df = df.drop(df.columns[0], axis=1)\n",
        "\n",
        "# List of feature columns\n",
        "features = ['Ash (%)', 'C (%)', 'N(%)', 'O (%)']\n",
        "\n",
        "# Define multiple target variables\n",
        "target_variables = ['Quality', 'HTL yield']\n",
        "\n",
        "# Fill NaN values with the mean of each column (for both features and target variables)\n",
        "df[features + target_variables] = df[features + target_variables].fillna(df.mean())\n",
        "\n",
        "# Dictionary to hold the performance results\n",
        "results = {}\n",
        "\n",
        "# Loop over each target variable to train and evaluate models for each\n",
        "for target_variable in target_variables:\n",
        "    # Prepare the feature set (X) and current target variable (y)\n",
        "    X = df[features]\n",
        "    y = df[target_variable]\n",
        "\n",
        "    # Split the data into training and testing sets (80% training, 20% testing)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the models to evaluate\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Random Forest\": RandomForestRegressor(),\n",
        "        \"Support Vector Regressor\": SVR(),\n",
        "        \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor()\n",
        "    }\n",
        "\n",
        "    # Evaluate each model\n",
        "    model_results = {}\n",
        "    for name, model in models.items():\n",
        "        # Fit the model on the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test data\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Calculate Mean Absolute Error (MAE) and RÂ² for model evaluation\n",
        "        mae = mean_absolute_error(y_test, predictions)\n",
        "        r2 = r2_score(y_test, predictions)\n",
        "\n",
        "        # Store the result in the dictionary\n",
        "        model_results[name] = {'MAE': mae, 'RÂ²': r2}\n",
        "\n",
        "        # Print the result for this model\n",
        "        print(f\"{target_variable} - {name}: MAE = {mae:.4f}, RÂ² = {r2:.4f}\")\n",
        "\n",
        "    # Store the results for each target variable\n",
        "    results[target_variable] = model_results\n",
        "\n",
        "    # Identify the best model for the current target variable (the model with the lowest MAE and highest RÂ²)\n",
        "    best_model_name = min(model_results, key=lambda x: model_results[x]['MAE'])\n",
        "    best_model_mae = model_results[best_model_name]['MAE']\n",
        "    best_model_r2 = model_results[best_model_name]['RÂ²']\n",
        "\n",
        "    # Output the best model and its performance for the current target variable\n",
        "    print(f\"\\nBest Model for {target_variable}: {best_model_name} with MAE = {best_model_mae:.4f} and RÂ² = {best_model_r2:.4f}\\n\")"
      ],
      "metadata": {
        "id": "I-8OKAoiJfU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partial dependence plots"
      ],
      "metadata": {
        "id": "7RqJH3zxC_xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install specific versions of libraries\n",
        "!pip install pandas==2.2.2 numpy==1.23.5 matplotlib seaborn scikit-learn openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load your dataset\n",
        "try:\n",
        "    df = pd.read_excel('/content/cleaned_data_no_missing_values_numerical.xlsx')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Two-way Partial Dependence Plot (Now only pairs of features)\n",
        "# Define pairs of features for two-way plots (now using two features per plot)\n",
        "features_two_way = [\n",
        "    ('C(%)', 'C'),\n",
        "    ('N (%)', 'N'),\n",
        "    ('O (%)', 'O'),\n",
        "    ('Reaction Time', 'Pore Size'),\n",
        "    ('Pore Volume', 'H2-TPR Peak Temperature'),\n",
        "    ('Reaction Temperature', 'Ni Loading')\n",
        "]\n",
        "\n",
        "# Loop through each pair and create a 2D PDP for it\n",
        "for feature_pair in features_two_way:\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    PartialDependenceDisplay.from_estimator(best_rf_model, X_train, features=[feature_pair], ax=ax, grid_resolution=50)\n",
        "    plt.title(f'Two-Way Partial Dependence Plot for {feature_pair}')\n",
        "    plt.show()\n",
        "\n",
        "# For multiple target variables, you can repeat the above steps in a loop\n",
        "for target_variable in target_variables:\n",
        "    # Check if the target variable exists in the DataFrame\n",
        "    if target_variable not in df.columns:\n",
        "        print(f\"Target column '{target_variable}' not found. Skipping this target.\")\n",
        "        continue\n",
        "\n",
        "    # Define features (X) and target variable (y)\n",
        "    y = df[target_variable]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Fit the model using RandomizedSearchCV\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Output the best parameters found by RandomizedSearchCV for the current target variable\n",
        "    print(f\"Best Parameters for {target_variable}: {random_search.best_params_}\")\n",
        "\n",
        "    # Refit the best model with the optimal parameters for the current target variable\n",
        "    best_rf_model = random_search.best_estimator_\n",
        "\n",
        "    # One-way Partial Dependence Plot for feature importance for the current target variable\n",
        "    features_one_way = ['Ni Particle Size','Ratio of CH4 in Feed','Modifier Electronegativity', 'GHSV', 'Ni Dispersion', 'Surface Area', 'Reaction Time', 'Pore Size', 'Pore Volume', 'H2-TPR Peak Temperature','Reaction Temperature', 'Ni Loading']  # Example features to plot\n",
        "\n",
        "    # Check if features exist in the DataFrame\n",
        "    for feature in features_one_way:\n",
        "        if feature not in X.columns:\n",
        "            raise ValueError(f\"Feature '{feature}' not found in the DataFrame.\")\n",
        "\n",
        "    # Create and display the Partial Dependence Plot for the current target variable\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    PartialDependenceDisplay.from_estimator(best_rf_model, X_train, features=features_one_way, ax=ax, grid_resolution=50)\n",
        "    plt.title(f'One-Way Partial Dependence Plots for {target_variable}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Z2sByb8gRgk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}